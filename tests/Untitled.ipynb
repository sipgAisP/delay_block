{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f429f-be50-4a67-be39-6891180e5fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image_paths=['1.jpg','2.jpg','3.jpg']\n",
    "# initialized a list of images\n",
    "imgs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747db192-8d56-4939-afd8-2afe42acece9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(image_paths)):\n",
    "\timgs.append(cv2.imread(image_paths[i]))\n",
    "\timgs[i]=cv2.resize(imgs[i],(0,0),fx=0.4,fy=0.4)\n",
    "\t# this is optional if your input images isn't too large\n",
    "\t# you don't need to scale down the image\n",
    "\t# in my case the input images are of dimensions 3000x1200\n",
    "\t# and due to this the resultant image won't fit the screen\n",
    "\t# scaling down the images\n",
    "# showing the original pictures\n",
    "cv2.imshow('1',imgs[0])\n",
    "cv2.imshow('2',imgs[1])\n",
    "cv2.imshow('3',imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a3a3e-40d4-49e6-acc9-7aecd9e50b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "stitchy=cv2.Stitcher.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595309a3-b664-40a5-916c-a2e4d3784de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "(dummy,output)=stitchy.stitch(imgs)\n",
    "\n",
    "if dummy != cv2.STITCHER_OK:\n",
    "# checking if the stitching procedure is successful\n",
    "# .stitch() function returns a true value if stitching is\n",
    "# done successfully\n",
    "\tprint(\"stitching ain't successful\")\n",
    "else:\n",
    "\tprint('Your Panorama is ready!!!')\n",
    "\n",
    "# final output\n",
    "cv2.imshow('final result',output)\n",
    "\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776f7399-6be9-4bac-a07b-91f8a1bc4191",
   "metadata": {},
   "outputs": [],
   "source": [
    "im=cv2.imread('images/golf.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3bf34a4-326a-4332-a1fc-c56a837d3cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray= cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c4d1aa8-6d32-4d88-92f7-5c1b496aa641",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "kp,d = sift.detectAndCompute(gray,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c85cf385-3640-4fdc-b41a-00156dfdb2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f=d.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "626ec939-9df8-4f5a-b663-3a62b866cda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8b7e0977-c024-41bf-b491-d6e6a28850da",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'cv2.KeyPoint' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pt \u001b[38;5;129;01min\u001b[39;00m kp:\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'cv2.KeyPoint' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "for pt in kp:\n",
    "    print(pt.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e00b27ee-7d46-4b74-acdb-dfaa99991f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SIFT in module cv2:\n",
      "\n",
      "class SIFT(Feature2D)\n",
      " |  Method resolution order:\n",
      " |      SIFT\n",
      " |      Feature2D\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  getDefaultName(...)\n",
      " |      getDefaultName() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  create(...)\n",
      " |      create([, nfeatures[, nOctaveLayers[, contrastThreshold[, edgeThreshold[, sigma]]]]]) -> retval\n",
      " |      .   @param nfeatures The number of best features to retain. The features are ranked by their scores\n",
      " |      .       (measured in SIFT algorithm as the local contrast)\n",
      " |      .   \n",
      " |      .       @param nOctaveLayers The number of layers in each octave. 3 is the value used in D. Lowe paper. The\n",
      " |      .       number of octaves is computed automatically from the image resolution.\n",
      " |      .   \n",
      " |      .       @param contrastThreshold The contrast threshold used to filter out weak features in semi-uniform\n",
      " |      .       (low-contrast) regions. The larger the threshold, the less features are produced by the detector.\n",
      " |      .   \n",
      " |      .       @note The contrast threshold will be divided by nOctaveLayers when the filtering is applied. When\n",
      " |      .       nOctaveLayers is set to default and if you want to use the value used in D. Lowe paper, 0.03, set\n",
      " |      .       this argument to 0.09.\n",
      " |      .   \n",
      " |      .       @param edgeThreshold The threshold used to filter out edge-like features. Note that the its meaning\n",
      " |      .       is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are\n",
      " |      .       filtered out (more features are retained).\n",
      " |      .   \n",
      " |      .       @param sigma The sigma of the Gaussian applied to the input image at the octave \\#0. If your image\n",
      " |      .       is captured with a weak camera with soft lenses, you might want to reduce the number.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      create(nfeatures, nOctaveLayers, contrastThreshold, edgeThreshold, sigma, descriptorType) -> retval\n",
      " |      .   @brief Create SIFT with specified descriptorType.\n",
      " |      .       @param nfeatures The number of best features to retain. The features are ranked by their scores\n",
      " |      .       (measured in SIFT algorithm as the local contrast)\n",
      " |      .   \n",
      " |      .       @param nOctaveLayers The number of layers in each octave. 3 is the value used in D. Lowe paper. The\n",
      " |      .       number of octaves is computed automatically from the image resolution.\n",
      " |      .   \n",
      " |      .       @param contrastThreshold The contrast threshold used to filter out weak features in semi-uniform\n",
      " |      .       (low-contrast) regions. The larger the threshold, the less features are produced by the detector.\n",
      " |      .   \n",
      " |      .       @note The contrast threshold will be divided by nOctaveLayers when the filtering is applied. When\n",
      " |      .       nOctaveLayers is set to default and if you want to use the value used in D. Lowe paper, 0.03, set\n",
      " |      .       this argument to 0.09.\n",
      " |      .   \n",
      " |      .       @param edgeThreshold The threshold used to filter out edge-like features. Note that the its meaning\n",
      " |      .       is different from the contrastThreshold, i.e. the larger the edgeThreshold, the less features are\n",
      " |      .       filtered out (more features are retained).\n",
      " |      .   \n",
      " |      .       @param sigma The sigma of the Gaussian applied to the input image at the octave \\#0. If your image\n",
      " |      .       is captured with a weak camera with soft lenses, you might want to reduce the number.\n",
      " |      .   \n",
      " |      .       @param descriptorType The type of descriptors. Only CV_32F and CV_8U are supported.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Feature2D:\n",
      " |  \n",
      " |  compute(...)\n",
      " |      compute(image, keypoints[, descriptors]) -> keypoints, descriptors\n",
      " |      .   @brief Computes the descriptors for a set of keypoints detected in an image (first variant) or image set\n",
      " |      .       (second variant).\n",
      " |      .   \n",
      " |      .       @param image Image.\n",
      " |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      " |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      " |      .       with several dominant orientations (for each orientation).\n",
      " |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      " |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      " |      .       descriptor for keypoint j-th keypoint.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      compute(images, keypoints[, descriptors]) -> keypoints, descriptors\n",
      " |      .   @overload\n",
      " |      .   \n",
      " |      .       @param images Image set.\n",
      " |      .       @param keypoints Input collection of keypoints. Keypoints for which a descriptor cannot be\n",
      " |      .       computed are removed. Sometimes new keypoints can be added, for example: SIFT duplicates keypoint\n",
      " |      .       with several dominant orientations (for each orientation).\n",
      " |      .       @param descriptors Computed descriptors. In the second variant of the method descriptors[i] are\n",
      " |      .       descriptors computed for a keypoints[i]. Row j is the keypoints (or keypoints[i]) is the\n",
      " |      .       descriptor for keypoint j-th keypoint.\n",
      " |  \n",
      " |  defaultNorm(...)\n",
      " |      defaultNorm() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  descriptorSize(...)\n",
      " |      descriptorSize() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  descriptorType(...)\n",
      " |      descriptorType() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  detect(...)\n",
      " |      detect(image[, mask]) -> keypoints\n",
      " |      .   @brief Detects keypoints in an image (first variant) or image set (second variant).\n",
      " |      .   \n",
      " |      .       @param image Image.\n",
      " |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      " |      .       of keypoints detected in images[i] .\n",
      " |      .       @param mask Mask specifying where to look for keypoints (optional). It must be a 8-bit integer\n",
      " |      .       matrix with non-zero values in the region of interest.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      detect(images[, masks]) -> keypoints\n",
      " |      .   @overload\n",
      " |      .       @param images Image set.\n",
      " |      .       @param keypoints The detected keypoints. In the second variant of the method keypoints[i] is a set\n",
      " |      .       of keypoints detected in images[i] .\n",
      " |      .       @param masks Masks for each input image specifying where to look for keypoints (optional).\n",
      " |      .       masks[i] is a mask for images[i].\n",
      " |  \n",
      " |  detectAndCompute(...)\n",
      " |      detectAndCompute(image, mask[, descriptors[, useProvidedKeypoints]]) -> keypoints, descriptors\n",
      " |      .   Detects keypoints and computes the descriptors\n",
      " |  \n",
      " |  empty(...)\n",
      " |      empty() -> retval\n",
      " |      .\n",
      " |  \n",
      " |  read(...)\n",
      " |      read(fileName) -> None\n",
      " |      .   \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      read(arg1) -> None\n",
      " |      .\n",
      " |  \n",
      " |  write(...)\n",
      " |      write(fileName) -> None\n",
      " |      .   \n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      write(fs[, name]) -> None\n",
      " |      .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.SIFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa08e9-d8d4-4db2-be5c-b98d3f00c247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
